{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from queue import Empty\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quello che viene fatto è fare scraping attraverso https://fbref.com/it/comp/11/2021-2022/Statistiche-di-Serie-A-2021-2022 nella stagione 2021-2022 e vengono estratte tutte le informazioni relative alle varie squadre che giocano nella stagione. \n",
    "\n",
    "I dati provenienti da diversi link vengono mergiati. \n",
    "Per poter classificare ho pensato a 3 classi: V (vittoria), P (persa), N (pareggio).\n",
    "Il problema è che scaricando tutte le partite per tutte le squadre, ci saranno partite doppie, ad esempio: \n",
    "- Atalanta V Bologna\n",
    "- Bologna P Atalanta\n",
    "\n",
    "Per questo vado a considerare nella classificazione solo le squadre in casa, così quando si vuole predire il risultato di una partita, ottengo la classificazione per la squadra di casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Serie A matches\n",
    "Per la realizzazione del dataset ho trovato in letteratura l'elenco dei dati più importanti per la predizione dei risultati delle partite. \n",
    "\n",
    "https://iopscience.iop.org/article/10.1088/1757-899X/226/1/012099/pdf\n",
    "\n",
    "Per questo dataset ho utilizzato le statistiche della stagione 2021/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': \n",
    "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "\n",
    "page = \"https://fbref.com/it/comp/11/2021-2022/Statistiche-di-Serie-A-2021-2022\"\n",
    "pageTree = requests.get(page)\n",
    "soup = BeautifulSoup(pageTree.text, features=\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.select('table.stats_table')[0]\n",
    "a_hrefs = table.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dizionario ha come chiave il campo estratto dalle colonne nelle tabelle dei vari link, mentre come valore la stringa con la quale deve essere sostituito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_fields = {\n",
    "    'Squadra': 'team',\n",
    "    'Avversario': 'avv',\n",
    "    'Rf': 'goals',\n",
    "    'Rs': 'gs',\n",
    "    'Tiri': 'total_shots',\n",
    "    'Tiri.1': 'shots_on_target',\n",
    "    'Rigori': 'goals_on_penalty',\n",
    "    'Rig T': 'total_penalties',\n",
    "    'Compl': 'completed_passings',\n",
    "    'Tent': 'total_passings',\n",
    "    'Angoli': 'corners',\n",
    "    'Poss.': 'percentage_possession',\n",
    "    'Falli': 'fouls',\n",
    "    'Amm.': 'yellow_cards',\n",
    "    'Esp.': 'red_cards',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [a_href for a_href in a_hrefs if '/squadre/' in str(a_href)]        \n",
    "#for team in teams:\n",
    "teams.sort(key=lambda x: x.contents[0]) #ordinamento per titolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa sezione vado ad estrarre il dataset completo di tutte le partite giocate per ogni squadra\n",
    "\n",
    "Il dizionario sottostante contiene come chiave i link ai bottoni che permettono di portare ai link dei vari dataset della squadra e come valore il nome della parte di html che permette di accedere al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_hrefs = {\n",
    "    'all_comps/shooting/': {\n",
    "        'section': 'Tiri',\n",
    "        'columns': ['Data', 'Tiri','Tiri.1','Rigori','Rig T']\n",
    "        },\n",
    "    'all_comps/passing/': {\n",
    "        'section': 'Passaggi',\n",
    "        'columns': ['Data', 'Compl.', 'Tent,']\n",
    "        },\n",
    "        \n",
    "    'all_comps/passing_types': {\n",
    "        'section': 'Tipologie di passaggi',\n",
    "        'columns': ['Data', 'Angoli']\n",
    "        },\n",
    "    'all_comps/possession': {\n",
    "        'section': 'Possesso palla',\n",
    "        'columns': ['Data', 'Poss.']\n",
    "        },\n",
    "    'all_comps/misc': {\n",
    "        'section': 'Statistiche varie',\n",
    "        'columns': ['Data', 'Falli', 'Amm.', 'Esp.']\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.DataFrame()\n",
    "home_games = pd.DataFrame()\n",
    "away_games = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:48<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for team in tqdm(teams):\n",
    "    team_name = team.contents[0]\n",
    "    link = f\"https://fbref.com{team.get('href')}\"\n",
    "    data = requests.get(link)\n",
    "    games = pd.read_html(data.text, match=\"Punteggi e partite\")[0]\n",
    "\n",
    "    matches = games[games['Competizione'] == 'Serie A']\n",
    "    matches = matches[['Data', 'Stadio', 'Risultato', 'Rf','Avversario','Rs']]\n",
    "    #match[home_main_factors[0]] = team_name\n",
    "    matches.insert(0, \"Squadra\", team_name)\n",
    "    #matches = matches.rename(columns={'Rf': home_main_factors[1], 'Avversario': away_main_factors[0], 'Rs': away_main_factors[1]})\n",
    "    \n",
    "    #ottengo il dataset della singola squadra con tutti i dati che servono\n",
    "    soup = BeautifulSoup(data.text, features=\"lxml\")\n",
    "    links = soup.find_all('a')\n",
    "    href_links = [l.get(\"href\") for l in links]\n",
    "\n",
    "    old_dataset = matches\n",
    "    for href_key, section_value in util_hrefs.items():\n",
    "        div_links = [l for l in href_links if l and href_key in l]\n",
    "        #prendo il link e ottengo l'html\n",
    "        html = requests.get(f\"https://fbref.com{div_links[0]}\")\n",
    "        \n",
    "        section, columns = section_value.items()\n",
    "        section, columns = section[1], columns[1]\n",
    "        #ottengo il dataset della pima sezione indicata nel match\n",
    "        dataset_section = pd.read_html(html.text, match=section)[0]\n",
    "        #elimino l'intestazione \"Di: NomeSquadra\"\n",
    "        dataset_section.columns = dataset_section.columns.droplevel()\n",
    "        #filtro il dataset per la competizione\n",
    "        dataset_section = dataset_section[dataset_section['Competizione'] == 'Serie A']\n",
    "        #filtro il dataset per le colonne selezionate\n",
    "        dataset_section = dataset_section[[col for col in columns]]\n",
    "        #print(dataset_section.columns)\n",
    "        if section == 'Passaggi':\n",
    "            column_names = dataset_section.columns.values\n",
    "            column_names[1] = 'Compl'\n",
    "            column_names[5] = 'Tent'\n",
    "            dataset_section = dataset_section[['Data','Compl','Tent']]\n",
    "\n",
    "        old_dataset = pd.merge(old_dataset, dataset_section, on = [\"Data\"])\n",
    "        \n",
    "    datasets = datasets.append(old_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo i due dataset, quello con le partite di casa e quello con quelle in trasferta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760 380 380\n"
     ]
    }
   ],
   "source": [
    "home_games = datasets[datasets['Stadio']=='Casa']\n",
    "away_games = datasets[datasets['Stadio']=='Ospiti']\n",
    "\n",
    "print(len(datasets), len(home_games), len(away_games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_home_fields = {key: 'h_'+value for key, value in rename_fields.items()}\n",
    "rename_home = rename_home_fields\n",
    "rename_home['Rs'] = 'a_goals'\n",
    "rename_home['Avversario'] = 'a_team'\n",
    "\n",
    "rename_away_fields = {key: 'a_'+value for key, value in rename_fields.items()}\n",
    "rename_away = rename_away_fields\n",
    "rename_away['Rs'] = 'h_goals'\n",
    "rename_away['Avversario'] = 'h_team'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_games = home_games.rename(columns=rename_home)\n",
    "away_games = away_games.rename(columns=rename_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_games.to_csv(\"homes.csv\")\n",
    "away_games.to_csv(\"aways.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_matches = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controllo dimensioni dataset, che dovrebbero essere 20*16 partite ciascuno, quindi 380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 380\n"
     ]
    }
   ],
   "source": [
    "print(len(home_games), len(away_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match delle stesse partite\n",
    "Il dataset iniziale contiene tutte le partite da tutte le squadre, quindi si passa da un dataset di n elementi ad un dataset di n/2.\n",
    "Matcho ogni partita del dataset home con la partita corrispondente del dataset away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_columns_needed = [\"a_team\", \"a_total_shots\", \"a_shots_on_target\", \"a_goals_on_penalty\", \"a_total_penalties\", \"a_corners\", \"a_yellow_cards\", \"a_red_cards\", \"a_fouls\", \"a_completed_passings\",  \"a_total_passings\", \"a_percentage_possession\", \"Data\", \"home_team\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, home_match in home_games.iterrows():\n",
    "    away_match = away_games[(away_games['Data'] == home_match['Data']) & (away_games['h_team'] == home_match['h_team']) & (away_games['a_team'] == home_match['a_team'])]\n",
    "    away_match_reduced = away_match[away_columns_needed]\n",
    "    home_match = pd.merge(home_match.to_frame().T, away_match_reduced, on = [\"Data\", \"h_team\", \"a_team\"])\n",
    "    normalized_matches = normalized_matches.append(home_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordiniamo le partite secondo la data in cui vengono giocate, perché se il modello voglio allenarlo con le ultime 5 partite, mi basta prendere le 5 più recenti in base all'ordine in cui sono salvate nel file csv. Una volta ordinato il dataset per Data della partita, elimino le colonne Stadio e Data tanto non mi servono per la classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Stadio'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9289324ee1bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnormalized_matches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_matches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d-%m-%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnormalized_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_matches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormalized_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_matches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stadio'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4905\u001b[0m         \"\"\"\n\u001b[0;32m-> 4906\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Stadio'] not found in axis\""
     ]
    }
   ],
   "source": [
    "normalized_matches['Data'] = pd.to_datetime(normalized_matches['Data'], format='%d-%m-%Y')\n",
    "normalized_matches = normalized_matches.sort_values(by=['Data'], ascending=True)\n",
    "normalized_matches = normalized_matches.drop(columns=['Stadio', \"Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_matches.to_csv(\"normalized_matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['h_team', 'Data', 'Stadio_x', 'Risultato_x', 'h_goals_x', 'a_team',\n",
       "       'a_goals_x', 'h_total_shots', 'h_shots_on_target', 'h_goals_on_penalty',\n",
       "       'h_total_penalties', 'h_completed_passings', 'h_total_passings',\n",
       "       'h_corners', 'h_percentage_possession', 'h_fouls', 'h_yellow_cards',\n",
       "       'h_red_cards', 'Stadio_y', 'Risultato_y', 'a_goals_y', 'h_goals_y',\n",
       "       'a_total_shots', 'a_shots_on_target', 'a_goals_on_penalty',\n",
       "       'a_total_penalties', 'a_completed_passings', 'a_total_passings',\n",
       "       'a_corners', 'a_percentage_possession', 'a_fouls', 'a_yellow_cards',\n",
       "       'a_red_cards'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_matches.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b51fba03621ea2707aa24f127a4f74542be1adffaa0a8f5a15c5b0606de1417a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
