{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of text analysis model\n",
    "I have seen that the decision tree is the model that offers me the best performance, especially with TfIdf and nltk/regex tokenization with PorterStemmer() stemming.\n",
    "\n",
    "The code pieces are the same as the code pieces of \"analysis.ipynb\", but this is needed for cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_tokenizer import MyTokenizer\n",
    "import pandas as pd\n",
    "import util_strings as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = MyTokenizer(pd.read_csv(utils.completed_dataset, index_col=0))\n",
    "mt.feature_normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.clean_text()\n",
    "vectorizer = True \n",
    "X_train, X_test, y_train, y_test = mt.set_bigram_and_get_sets(vectorizer) \n",
    "path_vec = utils.TfidfVectorizer if vectorizer else utils.CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificazione del modello\n",
    "Migliori risultati con Decision Tree.\n",
    "Viene salvato il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as mtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, y1, y2 = mt.set_bigram_and_get_sets2(vectorizer) \n",
    "\n",
    "matrix_training = mt.vectorizer.fit_transform(X1) #training set\n",
    "b = mt.vectorizer.transform(X2) #test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098159509202454"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(matrix_training, y1)\n",
    "\n",
    "y_pred = model.predict(b)\n",
    "report = mtr.classification_report(y2, y_pred, output_dict=True, zero_division=0)\n",
    "report['accuracy']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvataggio del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = utils.classificatorTfIdf if vectorizer else utils.classificatorCV_LR\n",
    "with open(file_name, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model\n",
    "A k-fold cross validation is used to validate the built model\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.61832061 0.66153846 0.76153846 0.83076923 0.84615385 0.79230769\n",
      " 0.76153846 0.76923077 0.78461538 0.76923077]\n",
      "Average CV Score:  0.7595243687610099\n",
      "Number of CV Scores used in Average:  10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "k_folds = KFold(n_splits = 10)\n",
    "scores = cross_val_score(model, matrix_training, y1, cv = k_folds)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth':  [2, 4, 6, 8, 10, 12],\n",
    "    'min_samples_split': [2,3,4],\n",
    "    'min_samples_leaf': [1,2]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    n_jobs=5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "model = clf.best_params_\n",
    "\n",
    "model.f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b51fba03621ea2707aa24f127a4f74542be1adffaa0a8f5a15c5b0606de1417a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
