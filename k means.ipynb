{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la realizzazione ho seguito https://www.datacamp.com/tutorial/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('description_predictions.csv', index_col=0)\n",
    "with open(\"sinonimi.json\") as jsonFile:\n",
    "    jsonObject = json.load(jsonFile)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_withoutNAN = dataset[dataset.prediction != 'NAN']\n",
    "\n",
    "dataset_withoutNAN.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice seguente serve per convertire i soprannomi delle squadre in home team e away team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in dataset_withoutNAN.iterrows():\n",
    "    h_team, a_team, description, prediction = row.h_team, row.a_team, row.description, row.prediction\n",
    "\n",
    "    syn = {}\n",
    "    #cerco nel dizionario di sinonimi, tutti i sinonimi delle squadre del match\n",
    "    for key in jsonObject.keys():\n",
    "        if (h_team in key) or (key in h_team):\n",
    "            syn['home team'] = jsonObject[key] \n",
    "            \n",
    "        if (a_team in key) or (key in a_team):\n",
    "            syn['away team'] = jsonObject[key] \n",
    "\n",
    "    #successivamente prendo il testo e sostituisco i sinonimi con home o away team\n",
    "    description = description.lower()\n",
    "    for key in syn.keys():\n",
    "        for val in syn[key]:\n",
    "            description = description.replace(val.lower(), key)\n",
    "\n",
    "    dataset_withoutNAN.at[i, 'description'] = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home team and away team take on each other in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home team begin their title defence with a mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>away team will look to make a flying start to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newcomers home team will be aiming to kick off...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after failing to impress in the 2020/21 serie ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  prediction\n",
       "0  home team and away team take on each other in ...           0\n",
       "1  home team begin their title defence with a mat...           1\n",
       "2  away team will look to make a flying start to ...           2\n",
       "3  newcomers home team will be aiming to kick off...           2\n",
       "4  after failing to impress in the 2020/21 serie ...           2"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_withoutNAN = dataset_withoutNAN[['description', 'prediction']]\n",
    "prediction_labels = {\n",
    "    'N': 0,\n",
    "    'V': 1,\n",
    "    'P': 2\n",
    "}\n",
    "\n",
    "dataset_withoutNAN['prediction'] = dataset_withoutNAN['prediction'].map(prediction_labels)\n",
    "dataset_withoutNAN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# this function returns a list of tokenized and stemmed words of any text\n",
    "def get_tokenized_list(doc_text):\n",
    "    tokens = nltk.word_tokenize(doc_text)\n",
    "    return tokens\n",
    "\n",
    "# This function will performing stemming on tokenized words\n",
    "def word_stemmer(token_list):\n",
    "  ps = nltk.stem.PorterStemmer()\n",
    "  stemmed = []\n",
    "  for words in token_list:\n",
    "    stemmed.append(ps.stem(words))\n",
    "  return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords from tokenized word list\n",
    "def remove_stopwords(doc_text):\n",
    "  cleaned_text = []\n",
    "  for words in doc_text:\n",
    "    if words not in stop_words:\n",
    "      cleaned_text.append(words)\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = []\n",
    "for doc in dataset_withoutNAN.description:\n",
    "  tokens = get_tokenized_list(doc)\n",
    "  doc_text = remove_stopwords(tokens)\n",
    "  doc_text  = word_stemmer(doc_text)\n",
    "  doc_text = ' '.join(doc_text)\n",
    "  cleaned_corpus.append(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2)) #vectorizer sarà il nostro modello da allenare\n",
    "text_counts = vectorizer.fit_transform(cleaned_corpus) #impara il vocabolario e crea Idf, poi ritorna la matrice document-term\n",
    "df1 = pd.DataFrame(text_counts.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, dataset_withoutNAN.prediction, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3).fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel seguente codice applico il k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as mtr\n",
    "import numpy as np \n",
    "import itertools\n",
    "\n",
    "label_classes = {\n",
    "    'N': 0,\n",
    "    'V': 1,\n",
    "    'P': 2\n",
    "}\n",
    "inverted_label_classes = {v: k for k, v in label_classes.items()}\n",
    "\n",
    "classes = [0,1,2]\n",
    "\n",
    "#trovo tutte le combinazioni da 3 classi (0 = 'N', 1 = 'V', 2 = 'P')\n",
    "all_combinations = list(itertools.product(*[classes,classes,classes]))\n",
    "combinations = []\n",
    "#filtro le combinazioni con le 3 classi diverse: la funzione precedente mi dà anche AAA AAC AAB ecc. sono classi sporche, quindi le elimino\n",
    "for single_combination in all_combinations:\n",
    "    if single_combination[0]!=single_combination[1] and single_combination[0]!=single_combination[2] and single_combination[1]!=single_combination[2]:\n",
    "        combinations.append([(0,single_combination[0]), (1,single_combination[1]), (2,single_combination[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando faccio il k means i documenti simili vengono raggruppati tra di loro, ma non so effettivamente se è corretta l'etichetta che viene assegnata a ciascun cluster.\n",
    "In poche parole, tutte le partite che vedono come vincitrice la squadra di home dovrebbero essere raggruppate sotto l'etichetta '1', ma può essere che l'etichetta sia 0 e quando si misura l'accuratezza ovviamente avrò un risultato basso. \n",
    "Per questo devo trovare tutte le combinazioni possibili di etichette: \n",
    "- Cluster1, Cluster2, Cluster3 --> 0, 1, 2\n",
    "- Cluster1, Cluster2, Cluster3 --> 0, 2, 1\n",
    "- Cluster1, Cluster2, Cluster3 --> 1, 0, 2\n",
    "- Cluster1, Cluster2, Cluster3 --> 1, 2, 0\n",
    "- Cluster1, Cluster2, Cluster3 --> 2, 0, 1\n",
    "- Cluster1, Cluster2, Cluster3 --> 2, 1, 0\n",
    "In questo modo poi vado a vedere quale di questi cluster ha l'accuratezza migliore e tengo.\n",
    "\n",
    "Itero ciascuna combinazione e calcolo l'accuratezza di quella combinazione con y_test e prendo l'accuratezza maggiore. \n",
    "Successivamente applico la combinazione che dà maggiore accuratezza al k_means e la stampo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0 #nessun kmeans darà 0, quindi se lo trovo maggiore ho trovato il miglior score locale\n",
    "best_kmean = []\n",
    "\n",
    "initial_labels = np.unique(y_test)\n",
    "original_prediction = kmeans.predict(X_test)\n",
    "\n",
    "for combination in combinations:\n",
    "    prediction = original_prediction.copy()\n",
    "    for convertion in combination:\n",
    "        prediction[prediction == convertion[0]] = ord(inverted_label_classes[convertion[1]])        \n",
    "    for letter, single_class in label_classes.items():\n",
    "        prediction[prediction == ord(letter)] = single_class\n",
    "    \n",
    "    score = mtr.accuracy_score(y_test, prediction)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_kmean = combination #tengo la combinazione delle classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4342105263157895,\n",
       " array([0, 1, 2, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 2, 1, 0, 2, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 2, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 1, 0], dtype=int32))"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if best_kmean:\n",
    "    for convertion in best_kmean:\n",
    "        original_prediction[original_prediction == convertion[0]] = ord(inverted_label_classes[convertion[1]])\n",
    "    for letter, single_class in label_classes.items():\n",
    "        original_prediction[original_prediction == ord(letter)] = single_class\n",
    "    \n",
    "score = mtr.accuracy_score(y_test, original_prediction)\n",
    "score, original_prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b51fba03621ea2707aa24f127a4f74542be1adffaa0a8f5a15c5b0606de1417a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
