{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la realizzazione ho seguito https://www.datacamp.com/tutorial/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('description_predictions.csv', index_col=0)\n",
    "with open(\"sinonimi.json\") as jsonFile:\n",
    "    jsonObject = json.load(jsonFile)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_withoutNAN = dataset[dataset.prediction != 'NAN']\n",
    "\n",
    "dataset_withoutNAN.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice seguente serve per convertire i soprannomi delle squadre in home team e away team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in dataset_withoutNAN.iterrows():\n",
    "    h_team, a_team, description, prediction = row.h_team, row.a_team, row.description, row.prediction\n",
    "\n",
    "    syn = {}\n",
    "    #cerco nel dizionario di sinonimi, tutti i sinonimi delle squadre del match\n",
    "    for key in jsonObject.keys():\n",
    "        if (h_team in key) or (key in h_team):\n",
    "            syn['home team'] = jsonObject[key] \n",
    "            \n",
    "        if (a_team in key) or (key in a_team):\n",
    "            syn['away team'] = jsonObject[key] \n",
    "\n",
    "    #successivamente prendo il testo e sostituisco i sinonimi con home o away team\n",
    "    description = description.lower()\n",
    "    for key in syn.keys():\n",
    "        for val in syn[key]:\n",
    "            description = description.replace(val.lower(), key)\n",
    "\n",
    "    dataset_withoutNAN.at[i, 'description'] = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home team and away team take on each other in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home team begin their title defence with a mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>away team will look to make a flying start to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newcomers home team will be aiming to kick off...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after failing to impress in the 2020/21 serie ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  prediction\n",
       "0  home team and away team take on each other in ...           0\n",
       "1  home team begin their title defence with a mat...           1\n",
       "2  away team will look to make a flying start to ...           2\n",
       "3  newcomers home team will be aiming to kick off...           2\n",
       "4  after failing to impress in the 2020/21 serie ...           2"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_withoutNAN = dataset_withoutNAN[['description', 'prediction']]\n",
    "prediction_labels = {\n",
    "    'N': 0,\n",
    "    'V': 1,\n",
    "    'P': 2\n",
    "}\n",
    "\n",
    "dataset_withoutNAN['prediction'] = dataset_withoutNAN['prediction'].map(prediction_labels)\n",
    "dataset_withoutNAN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# this function returns a list of tokenized and stemmed words of any text\n",
    "def get_tokenized_list(doc_text):\n",
    "    tokens = nltk.word_tokenize(doc_text)\n",
    "    return tokens\n",
    "\n",
    "# This function will performing stemming on tokenized words\n",
    "def word_stemmer(token_list):\n",
    "  ps = nltk.stem.PorterStemmer()\n",
    "  stemmed = []\n",
    "  for words in token_list:\n",
    "    stemmed.append(ps.stem(words))\n",
    "  return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords from tokenized word list\n",
    "def remove_stopwords(doc_text):\n",
    "  cleaned_text = []\n",
    "  for words in doc_text:\n",
    "    if words not in stop_words:\n",
    "      cleaned_text.append(words)\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = []\n",
    "for doc in dataset_withoutNAN.description:\n",
    "  tokens = get_tokenized_list(doc)\n",
    "  doc_text = remove_stopwords(tokens)\n",
    "  doc_text  = word_stemmer(doc_text)\n",
    "  doc_text = ' '.join(doc_text)\n",
    "  cleaned_corpus.append(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2)) #vectorizer sarà il nostro modello da allenare\n",
    "text_counts = vectorizer.fit_transform(cleaned_corpus) #impara il vocabolario e crea Idf, poi ritorna la matrice document-term\n",
    "df1 = pd.DataFrame(text_counts.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, dataset_withoutNAN.prediction, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3).fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel seguente codice applico il k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as mtr\n",
    "import numpy as np \n",
    "\n",
    "label_classes = {\n",
    "    'N': 0,\n",
    "    'V': 1,\n",
    "    'P': 2\n",
    "}\n",
    "\n",
    "classes = [0,1,2]\n",
    "\n",
    "import itertools\n",
    "\n",
    "#trovo tutte le combinazioni da 3 classi (0 = 'N', 1 = 'V', 2 = 'P')\n",
    "combinations = list(itertools.product(*[classes,classes,classes]))\n",
    "combs = {}\n",
    "i = 0\n",
    "\n",
    "#filtro le combinazioni con le 3 classi diverse: la funzione precedente mi dà anche AAA AAC AAB ecc. sono classi sporche, quindi le elimino\n",
    "for comb in combinations:\n",
    "    dict_comb={}\n",
    "    if comb[0]!=comb[1] and comb[0]!=comb[2] and comb[1]!=comb[2]:\n",
    "        dict_comb['N']=comb[0]\n",
    "        dict_comb['V']=comb[1]\n",
    "        dict_comb['P']=comb[2]\n",
    "        combs[i]=dict_comb\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo ottenuto diverse combinazioni di classi, ma avendo le 3 classi in ciascuna combinazione, non è detto che le etichette corrispondano al cluster corretto. \n",
    "Per questo motivo vado a trovare i cluster che mi danno un maggior score. \n",
    "Per questo ho creato un dizionario con associata la classe: \n",
    "- per ciascuna combinazione delle classi vado a sostituire il valore con un carattere temporaneo\n",
    "- sostituisco i valori dei caratteri con le relative classi della combinazione\n",
    "\n",
    "Faccio questo perché se avessi una predizione [0, 1, 0, 2], magari le etichette corrette hanno [1, 0, 1, 2] quindi le classi sono corrette ma sono sbagliati i nomi. Quindi devo cambiare i nomi delle varie classi e prendere la combinazione che mi dà il maggior valore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 1 1 2 2 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 1 1 0 1 1 1 1 1 1 2 2 2\n",
      " 2 1 2 1 1 1 2 0 2 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 2 1 2 1 1 0 1 0 0 2 1\n",
      " 1 0] 0.4342105263157895\n",
      "N 0\n",
      "V 2\n",
      "P 1\n",
      "[2 2 1 2 2 1 1 1 2 2 1 1 2 2 2 1 1 2 2 1 2 2 1 2 2 2 2 0 2 2 2 2 2 2 1 1 1\n",
      " 1 2 1 2 2 2 1 0 1 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 1 2 1 2 2 0 2 0 0 1 2\n",
      " 2 0] 0.35526315789473684\n",
      "N 1\n",
      "V 0\n",
      "P 2\n",
      "[0 0 2 0 0 2 2 2 0 0 2 2 0 0 0 2 2 0 0 2 0 0 2 0 0 0 0 1 0 0 0 0 0 0 2 2 2\n",
      " 2 0 2 0 0 0 2 1 2 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 2 0 2 0 0 1 0 1 1 2 0\n",
      " 0 1] 0.2894736842105263\n",
      "N 1\n",
      "V 2\n",
      "P 0\n",
      "[0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 2 0 0 0 0 0 0 1 1 1\n",
      " 1 0 1 0 0 0 1 2 1 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 1 0 1 0 0 2 0 2 2 1 0\n",
      " 0 2] 0.2894736842105263\n",
      "N 2\n",
      "V 0\n",
      "P 1\n",
      "[2 2 0 2 2 0 0 0 2 2 0 0 2 2 2 0 0 2 2 0 2 2 0 2 2 2 2 1 2 2 2 2 2 2 0 0 0\n",
      " 0 2 0 2 2 2 0 1 0 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 0 2 0 2 2 1 2 1 1 0 2\n",
      " 2 1] 0.27631578947368424\n",
      "N 2\n",
      "V 1\n",
      "P 0\n",
      "[1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 2 1 1 1 1 1 1 0 0 0\n",
      " 0 1 0 1 1 1 0 2 0 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 0 1 0 1 1 2 1 2 2 0 1\n",
      " 1 2] 0.35526315789473684\n"
     ]
    }
   ],
   "source": [
    "best_score = 0 #nessun kmeans darà 0, quindi se lo trovo maggiore ho trovato il miglior score\n",
    "best_kmeans = combs[0]\n",
    "\n",
    "prediction = kmeans.predict(X_test)\n",
    "original_prediction = prediction.copy()\n",
    "for combination, dict_classes in combs.items():\n",
    "    if combination != 0: #la prima combinazione è già fatta, quindi la salto\n",
    "        prediction = original_prediction.copy()\n",
    "        #prima cambio il contenuto dell'array con numeri temporanei\n",
    "        for letter, single_class in dict_classes.items():\n",
    "            prediction[prediction == single_class] = ord(letter) #ord permette di ottenere il codice decimale del carattere\n",
    "\n",
    "        #sostituisco i relativi valori con i relativi valori iniziali \n",
    "        for letter, single_class in label_classes.items():\n",
    "            prediction[prediction == ord('N')] = 0\n",
    "        \n",
    "    score = mtr.accuracy_score(y_test, prediction)\n",
    "    print(prediction, score)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_kmeans = dict_classes #tengo la combinazione delle classi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converto le classi secondo il dizionario con il massimo score. \n",
    "Non posso convertire ad esempio 0 in 1, 1 in 2 e 2 in 0, perché alla fine avrò tutti i numeri uguali, quindi devo usare un passaggio intermedio utilizzando altri numeri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 1 1 2 2 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 1 1 0 1 1 1 1 1 1 2 2 2\n",
      " 2 1 2 1 1 1 2 0 2 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 2 1 2 1 1 0 1 0 0 2 1\n",
      " 1 0] 0.4342105263157895\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for letter, single_class in best_kmeans.items():\n",
    "    original_prediction[original_prediction == single_class] = ord(letter)\n",
    "\n",
    "for letter, single_class in best_kmeans.items():\n",
    "    original_prediction[original_prediction == ord(letter)] = single_class\n",
    "    \n",
    "score = mtr.accuracy_score(y_test, original_prediction)\n",
    "print(original_prediction, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b51fba03621ea2707aa24f127a4f74542be1adffaa0a8f5a15c5b0606de1417a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
