{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la realizzazione ho seguito https://www.datacamp.com/tutorial/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('description_predictions.csv')\n",
    "with open(\"sinonimi.json\") as jsonFile:\n",
    "    jsonObject = json.load(jsonFile)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-415-3e36f7bd9202>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_withoutNAN['index'] = range_index\n"
     ]
    }
   ],
   "source": [
    "dataset_withoutNAN = dataset[dataset.prediction != 'NAN']\n",
    "\n",
    "range_index = [i for i in range(len(dataset_withoutNAN))]\n",
    "dataset_withoutNAN['index'] = range_index \n",
    "\n",
    "dataset_withoutNAN = dataset_withoutNAN.set_index('index') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice seguente serve per convertire i soprannomi delle squadre in home team e away team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i, row in dataset_withoutNAN.iterrows():\n",
    "    h_team, a_team, description, prediction = row.h_team, row.a_team, row.description, row.prediction\n",
    "\n",
    "    syn = {}\n",
    "    #cerco nel dizionario di sinonimi, tutti i sinonimi delle squadre del match\n",
    "    for key in jsonObject.keys():\n",
    "        if (h_team in key) or (key in h_team):\n",
    "            syn['home team'] = jsonObject[key] \n",
    "            \n",
    "        if (a_team in key) or (key in a_team):\n",
    "            syn['away team'] = jsonObject[key] \n",
    "\n",
    "    #successivamente prendo il testo e sostituisco i sinonimi con home o away team\n",
    "    description = description.lower()\n",
    "    for key in syn.keys():\n",
    "        for val in syn[key]:\n",
    "            description = description.replace(val.lower(), key)\n",
    "\n",
    "    dataset_withoutNAN.at[i, 'description'] = description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home team and away team take on each other in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home team begin their title defence with a mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>away team will look to make a flying start to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newcomers home team will be aiming to kick off...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after failing to impress in the 2020/21 serie ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  prediction\n",
       "index                                                               \n",
       "0      home team and away team take on each other in ...           0\n",
       "1      home team begin their title defence with a mat...           1\n",
       "2      away team will look to make a flying start to ...           2\n",
       "3      newcomers home team will be aiming to kick off...           2\n",
       "4      after failing to impress in the 2020/21 serie ...           2"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_withoutNAN = dataset_withoutNAN[['description', 'prediction']]\n",
    "prediction_labels = {\n",
    "    'N': 0,\n",
    "    'V': 1,\n",
    "    'P': 2\n",
    "}\n",
    "\n",
    "dataset_withoutNAN['prediction'] = dataset_withoutNAN['prediction'].map(prediction_labels)\n",
    "dataset_withoutNAN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True, stop_words='english', ngram_range = (2,2), tokenizer = token.tokenize)\n",
    "text_counts= cv.fit_transform(dataset_withoutNAN.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, dataset_withoutNAN.prediction, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as mtr\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000), #max_iter di default vale 100, ho dovuto alzarlo se no non converge\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    models[model_name].fit(X_train, y_train)\n",
    "    predictions[model_name] = model.predict(X_test)\n",
    "\n",
    "E = []\n",
    "for estimator, y_pred in predictions.items():\n",
    "    report = mtr.classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    E.append({\n",
    "        'Model': estimator, 'Accuracy': report['accuracy'],\n",
    "        'Avg Precision (macro)': report['macro avg']['precision'],\n",
    "        'Avg Recall (macro)': report['macro avg']['recall'],\n",
    "        'Avg F1-score (macro)': report['macro avg']['f1-score'],\n",
    "        'Avg Precision (weighted)': report['weighted avg']['precision'],\n",
    "        'Avg Recall (weighted)': report['weighted avg']['recall'],\n",
    "        'Avg F1-score (weighted)': report['weighted avg']['f1-score']\n",
    "    })\n",
    "E = pd.DataFrame(E).set_index('Model', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg Precision (macro)</th>\n",
       "      <th>Avg Recall (macro)</th>\n",
       "      <th>Avg F1-score (macro)</th>\n",
       "      <th>Avg Precision (weighted)</th>\n",
       "      <th>Avg Recall (weighted)</th>\n",
       "      <th>Avg F1-score (weighted)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy  Avg Precision (macro)  Avg Recall (macro)  \\\n",
       "Model                                                                          \n",
       "Logistic Regression      0.666667               0.333333            0.500000   \n",
       "Support Vector Machine   0.666667               0.333333            0.500000   \n",
       "Multinomial Naive Bayes  0.000000               0.000000            0.000000   \n",
       "Decision Tree            0.666667               0.333333            0.500000   \n",
       "Random Forest            0.666667               0.333333            0.500000   \n",
       "K-Nearest Neighbors      0.333333               0.333333            0.166667   \n",
       "\n",
       "                         Avg F1-score (macro)  Avg Precision (weighted)  \\\n",
       "Model                                                                     \n",
       "Logistic Regression                  0.400000                  0.444444   \n",
       "Support Vector Machine               0.400000                  0.444444   \n",
       "Multinomial Naive Bayes              0.000000                  0.000000   \n",
       "Decision Tree                        0.400000                  0.444444   \n",
       "Random Forest                        0.400000                  0.444444   \n",
       "K-Nearest Neighbors                  0.222222                  0.666667   \n",
       "\n",
       "                         Avg Recall (weighted)  Avg F1-score (weighted)  \n",
       "Model                                                                    \n",
       "Logistic Regression                   0.666667                 0.533333  \n",
       "Support Vector Machine                0.666667                 0.533333  \n",
       "Multinomial Naive Bayes               0.000000                 0.000000  \n",
       "Decision Tree                         0.666667                 0.533333  \n",
       "Random Forest                         0.666667                 0.533333  \n",
       "K-Nearest Neighbors                   0.333333                 0.444444  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b51fba03621ea2707aa24f127a4f74542be1adffaa0a8f5a15c5b0606de1417a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
