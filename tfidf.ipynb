{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecniche di ML a confronto\n",
    "In questo jupyter vengono confrontate le prestazioni delle varie classificazioni di ciascun modello.\n",
    "Il metodo utilizzato è TfIdf con una tokenizzazione nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la realizzazione ho seguito https://www.datacamp.com/tutorial/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('description_predictions.csv', index_col=0)\n",
    "with open(\"sinonimi.json\") as jsonFile:\n",
    "    jsonObject = json.load(jsonFile)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_withoutNAN = dataset[dataset.prediction != 'NAN']\n",
    "\n",
    "dataset_withoutNAN.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice seguente serve per convertire i soprannomi delle squadre in home team e away team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in dataset_withoutNAN.iterrows():\n",
    "    h_team, a_team, description, prediction = row.h_team, row.a_team, row.description, row.prediction\n",
    "\n",
    "    syn = {}\n",
    "    #cerco nel dizionario di sinonimi, tutti i sinonimi delle squadre del match\n",
    "    for key in jsonObject.keys():\n",
    "        if (h_team in key) or (key in h_team):\n",
    "            syn['home team'] = jsonObject[key] \n",
    "            \n",
    "        if (a_team in key) or (key in a_team):\n",
    "            syn['away team'] = jsonObject[key] \n",
    "\n",
    "    #successivamente prendo il testo e sostituisco i sinonimi con home o away team\n",
    "    description = description.lower()\n",
    "    for key in syn.keys():\n",
    "        for val in syn[key]:\n",
    "            description = description.replace(val.lower(), key)\n",
    "\n",
    "    dataset_withoutNAN.at[i, 'description'] = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home team and away team take on each other in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home team begin their title defence with a mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>away team will look to make a flying start to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newcomers home team will be aiming to kick off...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after failing to impress in the 2020/21 serie ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  prediction\n",
       "0  home team and away team take on each other in ...           0\n",
       "1  home team begin their title defence with a mat...           1\n",
       "2  away team will look to make a flying start to ...           2\n",
       "3  newcomers home team will be aiming to kick off...           2\n",
       "4  after failing to impress in the 2020/21 serie ...           2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_withoutNAN = dataset_withoutNAN[['description', 'prediction']]\n",
    "prediction_labels = {\n",
    "    'N': 0,\n",
    "    'V': 1,\n",
    "    'P': 2\n",
    "}\n",
    "\n",
    "dataset_withoutNAN['prediction'] = dataset_withoutNAN['prediction'].map(prediction_labels)\n",
    "dataset_withoutNAN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# this function returns a list of tokenized and stemmed words of any text\n",
    "def get_tokenized_list(doc_text):\n",
    "    tokens = nltk.word_tokenize(doc_text)\n",
    "    return tokens\n",
    "\n",
    "# This function will performing stemming on tokenized words\n",
    "def word_stemmer(token_list):\n",
    "  ps = nltk.stem.PorterStemmer()\n",
    "  stemmed = []\n",
    "  for words in token_list:\n",
    "    stemmed.append(ps.stem(words))\n",
    "  return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords from tokenized word list\n",
    "def remove_stopwords(doc_text):\n",
    "  cleaned_text = []\n",
    "  for words in doc_text:\n",
    "    if words not in stop_words:\n",
    "      cleaned_text.append(words)\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = []\n",
    "for doc in dataset_withoutNAN.description:\n",
    "  tokens = get_tokenized_list(doc)\n",
    "  doc_text = remove_stopwords(tokens)\n",
    "  doc_text  = word_stemmer(doc_text)\n",
    "  doc_text = ' '.join(doc_text)\n",
    "  cleaned_corpus.append(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2)) #vectorizer sarà il nostro modello da allenare\n",
    "text_counts = vectorizer.fit_transform(cleaned_corpus) #impara il vocabolario e crea Idf, poi ritorna la matrice document-term\n",
    "df1 = pd.DataFrame(text_counts.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, dataset_withoutNAN.prediction, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as mtr\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000), #max_iter di default vale 100, ho dovuto alzarlo se no non converge\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    models[model_name].fit(X_train, y_train)\n",
    "    predictions[model_name] = model.predict(X_test)\n",
    "\n",
    "E = []\n",
    "for estimator, y_pred in predictions.items():\n",
    "    report = mtr.classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    E.append({\n",
    "        'Model': estimator, 'Accuracy': report['accuracy'],\n",
    "        'Avg Precision (macro)': report['macro avg']['precision'],\n",
    "        'Avg Recall (macro)': report['macro avg']['recall'],\n",
    "        'Avg F1-score (macro)': report['macro avg']['f1-score'],\n",
    "        'Avg Precision (weighted)': report['weighted avg']['precision'],\n",
    "        'Avg Recall (weighted)': report['weighted avg']['recall'],\n",
    "        'Avg F1-score (weighted)': report['weighted avg']['f1-score']\n",
    "    })\n",
    "\n",
    "E = pd.DataFrame(E).set_index('Model', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg Precision (macro)</th>\n",
       "      <th>Avg Recall (macro)</th>\n",
       "      <th>Avg F1-score (macro)</th>\n",
       "      <th>Avg Precision (weighted)</th>\n",
       "      <th>Avg Recall (weighted)</th>\n",
       "      <th>Avg F1-score (weighted)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.286064</td>\n",
       "      <td>0.505104</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.355420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.152047</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208835</td>\n",
       "      <td>0.208064</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.285775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.152047</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208835</td>\n",
       "      <td>0.208064</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.285775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.776683</td>\n",
       "      <td>0.752967</td>\n",
       "      <td>0.762113</td>\n",
       "      <td>0.777115</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.771776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.827614</td>\n",
       "      <td>0.506444</td>\n",
       "      <td>0.469790</td>\n",
       "      <td>0.773908</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.522753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.659596</td>\n",
       "      <td>0.527751</td>\n",
       "      <td>0.513277</td>\n",
       "      <td>0.643567</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.553826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy  Avg Precision (macro)  Avg Recall (macro)  \\\n",
       "Model                                                                          \n",
       "Logistic Regression      0.491228               0.490909            0.373737   \n",
       "Support Vector Machine   0.456140               0.152047            0.333333   \n",
       "Multinomial Naive Bayes  0.456140               0.152047            0.333333   \n",
       "Decision Tree            0.771930               0.776683            0.752967   \n",
       "Random Forest            0.605263               0.827614            0.506444   \n",
       "K-Nearest Neighbors      0.596491               0.659596            0.527751   \n",
       "\n",
       "                         Avg F1-score (macro)  Avg Precision (weighted)  \\\n",
       "Model                                                                     \n",
       "Logistic Regression                  0.286064                  0.505104   \n",
       "Support Vector Machine               0.208835                  0.208064   \n",
       "Multinomial Naive Bayes              0.208835                  0.208064   \n",
       "Decision Tree                        0.762113                  0.777115   \n",
       "Random Forest                        0.469790                  0.773908   \n",
       "K-Nearest Neighbors                  0.513277                  0.643567   \n",
       "\n",
       "                         Avg Recall (weighted)  Avg F1-score (weighted)  \n",
       "Model                                                                    \n",
       "Logistic Regression                   0.491228                 0.355420  \n",
       "Support Vector Machine                0.456140                 0.285775  \n",
       "Multinomial Naive Bayes               0.456140                 0.285775  \n",
       "Decision Tree                         0.771930                 0.771776  \n",
       "Random Forest                         0.605263                 0.522753  \n",
       "K-Nearest Neighbors                   0.596491                 0.553826  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b51fba03621ea2707aa24f127a4f74542be1adffaa0a8f5a15c5b0606de1417a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
