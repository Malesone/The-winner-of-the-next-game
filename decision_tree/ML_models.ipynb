{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as mtr\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"merged_matches.csv\", index_col=0)\n",
    "dataset['Risultato'] = dataset[['Risultato']].replace(['V','P','N'],[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_without_goals = dataset.drop(columns=['h_team', 'a_team', 'h_goals', 'a_goals', 'h_goals_on_penalty', 'h_total_penalties', 'a_goals_on_penalty', 'a_total_penalties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in dataset_without_goals.columns if x != 'Risultato']\n",
    "X, y = dataset_without_goals[features], dataset_without_goals.Risultato.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonemalesardi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(\"Training: {}\".format(model_name))\n",
    "    models[model_name].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: Logistic Regression\n",
      "Predicting: Support Vector Machine\n",
      "Predicting: Multinomial Naive Bayes\n",
      "Predicting: Decision Tree\n",
      "Predicting: Random Forest\n",
      "Predicting: K-Nearest Neighbors\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    print(\"Predicting: {}\".format(model_name))\n",
    "    predictions[model_name] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "for estimator, y_pred in predictions.items():\n",
    "    report = mtr.classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    E.append({\n",
    "        'Model': estimator, 'Accuracy': report['accuracy'],\n",
    "        'Avg Precision (macro)': report['macro avg']['precision'],\n",
    "        'Avg Recall (macro)': report['macro avg']['recall'],\n",
    "        'Avg F1-score (macro)': report['macro avg']['f1-score'],\n",
    "        'Avg Precision (weighted)': report['weighted avg']['precision'],\n",
    "        'Avg Recall (weighted)': report['weighted avg']['recall'],\n",
    "        'Avg F1-score (weighted)': report['weighted avg']['f1-score']\n",
    "    })\n",
    "E = pd.DataFrame(E).set_index('Model', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg Precision (macro)</th>\n",
       "      <th>Avg Recall (macro)</th>\n",
       "      <th>Avg F1-score (macro)</th>\n",
       "      <th>Avg Precision (weighted)</th>\n",
       "      <th>Avg Recall (weighted)</th>\n",
       "      <th>Avg F1-score (weighted)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.537710</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.537670</td>\n",
       "      <td>0.552240</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.552001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.412281</td>\n",
       "      <td>0.285088</td>\n",
       "      <td>0.381197</td>\n",
       "      <td>0.312694</td>\n",
       "      <td>0.317521</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>0.343751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.440922</td>\n",
       "      <td>0.424786</td>\n",
       "      <td>0.414374</td>\n",
       "      <td>0.442278</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.423808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.454365</td>\n",
       "      <td>0.451567</td>\n",
       "      <td>0.447037</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.451125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.484058</td>\n",
       "      <td>0.494017</td>\n",
       "      <td>0.483688</td>\n",
       "      <td>0.507437</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.512172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.384940</td>\n",
       "      <td>0.386325</td>\n",
       "      <td>0.368309</td>\n",
       "      <td>0.395450</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.392285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy  Avg Precision (macro)  Avg Recall (macro)  \\\n",
       "Model                                                                          \n",
       "Logistic Regression      0.552632               0.537710            0.538462   \n",
       "Support Vector Machine   0.412281               0.285088            0.381197   \n",
       "Multinomial Naive Bayes  0.438596               0.440922            0.424786   \n",
       "Decision Tree            0.447368               0.454365            0.451567   \n",
       "Random Forest            0.526316               0.484058            0.494017   \n",
       "K-Nearest Neighbors      0.421053               0.384940            0.386325   \n",
       "\n",
       "                         Avg F1-score (macro)  Avg Precision (weighted)  \\\n",
       "Model                                                                     \n",
       "Logistic Regression                  0.537670                  0.552240   \n",
       "Support Vector Machine               0.312694                  0.317521   \n",
       "Multinomial Naive Bayes              0.414374                  0.442278   \n",
       "Decision Tree                        0.447037                  0.466917   \n",
       "Random Forest                        0.483688                  0.507437   \n",
       "K-Nearest Neighbors                  0.368309                  0.395450   \n",
       "\n",
       "                         Avg Recall (weighted)  Avg F1-score (weighted)  \n",
       "Model                                                                    \n",
       "Logistic Regression                   0.552632                 0.552001  \n",
       "Support Vector Machine                0.412281                 0.343751  \n",
       "Multinomial Naive Bayes               0.438596                 0.423808  \n",
       "Decision Tree                         0.447368                 0.451125  \n",
       "Random Forest                         0.526316                 0.512172  \n",
       "K-Nearest Neighbors                   0.421053                 0.392285  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b51fba03621ea2707aa24f127a4f74542be1adffaa0a8f5a15c5b0606de1417a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
